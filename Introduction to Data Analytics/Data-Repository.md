# Data Repository

A **Data Repository** is a general term that refers to data that has been collected, organized, and isolated in a way that it can be used for reporting, analysis, and archival purposes.

The different types of **Data Repositories** include:

- **Databases**, which can be relational or non-relational, each following a set of organizational principles, the types of data they can store, and the tools that can be used to query, organize, and retrieve data.

- **Data Warehouses**, which consolidate incoming data into a comprehensive store.

- **Data Marts**, which are essentially subsections of a data warehouse, built to isolate data for a particular business function or use case.

- **Data Lakes**, which serve as storage repositories for large amounts of structured, semi-structured, and unstructured data in its native format.

- **Big Data Warehouses**, which provide distributed computing and storage infrastructure for storing, scaling, and processing very large datasets.

**ETL**, or **Extract, Transform, Load**, is an automated process that converts raw data into data ready for analysis by:

1. Extracting data from source locations.
2. Transforming raw data by cleaning, enriching, normalizing, and validating it.
3. Loading processed data into a target system or data repository.

**Data Pipelining**, sometimes used interchangeably with ETL, encompasses the entire path of moving data from the source to a data lake or destination application, using the ETL process.

**Big Data** refers to the enormous amounts of data being produced every moment of every day by people, tools, and machines. The massive speed, volume, and variety of data pose a challenge for the tools and systems used for conventional data. These challenges led to the emergence of processing tools and platforms specifically designed for Big Data, such as Apache Hadoop, Apache Hive, and Apache Spark.