# Data Wrangling Process

Once you have gathered and imported the data you have identified, your next step is to prepare it for analysis. This is where the Data Wrangling process, or Data Munging, comes into play. Data Wrangling is an iterative process that involves exploring, transforming, and validating the data.

Transforming raw data includes tasks that are carried out to:

- Manipulate and structurally combine the data using Joins and Unions.
- Normalize the data, i.e., clean the database from unused and redundant data.
- Denormalize the data, i.e., combine data from multiple tables into one to query them more quickly.
- Clean the data, which involves profiling the data to discover quality issues, visualize the data to detect outliers, and address issues such as missing values, duplicate data, irrelevant data, inconsistent formats, syntax errors, and outliers.
- Enrich the data, which involves considering additional data points that could add value to the existing dataset and lead to more meaningful analysis.

There is a wide variety of software and tools for the Data Wrangling process. Some of the most commonly used ones are Excel Power Query, Spreadsheets, OpenRefine, Google DataPrep, Watson Studio Refinery, Trifacta Wrangler, Python, and R, each with its own set of features, strengths, limitations, and applications.
